{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Lab Session 4.Vision-Language Model (VLM) Prompt Tuning\n",
        "\n",
        "## Contents\n",
        "[1] Preparation \\\n",
        "[2] Load pre-trained CLIP Model \\\n",
        "[3] CoOpCLIP Implementation \\\n",
        "[4] CoOpCLIP Training\n",
        "\n",
        "\n",
        "## References\n",
        "- Learning to Prompt for Vision-Language Models (CoOp): https://github.com/KaiyangZhou/CoOp\n",
        "- Prompt Learning via Meta-Regularization (ProMetaR): https://github.com/mlvlab/ProMetaR"
      ],
      "metadata": {
        "id": "SlXBcE5Jyasd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "# [1] Preparation"
      ],
      "metadata": {
        "id": "33ucm40jy2ob"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Clone github repository"
      ],
      "metadata": {
        "id": "0k0iyRGO3nxY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/mlvlab/ProMetaR.git"
      ],
      "metadata": {
        "id": "p_N1HeFoj5Me",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fdab044f-eb14-4470-f452-c16fdb5d09ea"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'ProMetaR' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- It will make ProMetaR folder on left side."
      ],
      "metadata": {
        "id": "TbtCGMbbKR37"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Install Requirements"
      ],
      "metadata": {
        "id": "HZirgCYRzAia"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd ProMetaR/\n",
        "\n",
        "#!git clone https://github.com/KaiyangZhou/Dassl.pytorch.git\n",
        "%cd Dassl.pytorch/\n",
        "\n",
        "# Install dependencies\n",
        "#!pip install -r requirements.txt\n",
        "#!cp -r dassl ../\n",
        "# Install this library (no need to re-build if the source code is modified)\n",
        "# !python setup.py develop\n",
        "%cd ..\n",
        "\n",
        "!pip install -r requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MsVCEqXpzBjg",
        "outputId": "8f45894d-ac1a-44e0-8a81-b0bfafc8b231"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/ProMetaR\n",
            "/content/ProMetaR/Dassl.pytorch\n",
            "/content/ProMetaR\n",
            "Requirement already satisfied: ftfy==6.1.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 1)) (6.1.1)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 2)) (2024.9.11)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 3)) (4.66.6)\n",
            "Requirement already satisfied: learn2learn==0.2.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 4)) (0.2.0)\n",
            "Requirement already satisfied: wcwidth>=0.2.5 in /usr/local/lib/python3.10/dist-packages (from ftfy==6.1.1->-r requirements.txt (line 1)) (0.2.13)\n",
            "Requirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.10/dist-packages (from learn2learn==0.2.0->-r requirements.txt (line 4)) (1.26.4)\n",
            "Requirement already satisfied: gym>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from learn2learn==0.2.0->-r requirements.txt (line 4)) (0.25.2)\n",
            "Requirement already satisfied: torch>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from learn2learn==0.2.0->-r requirements.txt (line 4)) (2.5.0+cu121)\n",
            "Requirement already satisfied: torchvision>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from learn2learn==0.2.0->-r requirements.txt (line 4)) (0.20.0+cu121)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from learn2learn==0.2.0->-r requirements.txt (line 4)) (1.13.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from learn2learn==0.2.0->-r requirements.txt (line 4)) (2.32.3)\n",
            "Requirement already satisfied: gsutil in /usr/local/lib/python3.10/dist-packages (from learn2learn==0.2.0->-r requirements.txt (line 4)) (5.31)\n",
            "Requirement already satisfied: qpth>=0.0.15 in /usr/local/lib/python3.10/dist-packages (from learn2learn==0.2.0->-r requirements.txt (line 4)) (0.0.18)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gym>=0.14.0->learn2learn==0.2.0->-r requirements.txt (line 4)) (3.1.0)\n",
            "Requirement already satisfied: gym-notices>=0.0.4 in /usr/local/lib/python3.10/dist-packages (from gym>=0.14.0->learn2learn==0.2.0->-r requirements.txt (line 4)) (0.0.8)\n",
            "Requirement already satisfied: cvxpy>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from qpth>=0.0.15->learn2learn==0.2.0->-r requirements.txt (line 4)) (1.5.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.1.0->learn2learn==0.2.0->-r requirements.txt (line 4)) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.1.0->learn2learn==0.2.0->-r requirements.txt (line 4)) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.1.0->learn2learn==0.2.0->-r requirements.txt (line 4)) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.1.0->learn2learn==0.2.0->-r requirements.txt (line 4)) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.1.0->learn2learn==0.2.0->-r requirements.txt (line 4)) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.1.0->learn2learn==0.2.0->-r requirements.txt (line 4)) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.1.0->learn2learn==0.2.0->-r requirements.txt (line 4)) (1.3.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision>=0.3.0->learn2learn==0.2.0->-r requirements.txt (line 4)) (10.4.0)\n",
            "Requirement already satisfied: argcomplete>=1.9.4 in /usr/local/lib/python3.10/dist-packages (from gsutil->learn2learn==0.2.0->-r requirements.txt (line 4)) (3.5.1)\n",
            "Requirement already satisfied: crcmod>=1.7 in /usr/local/lib/python3.10/dist-packages (from gsutil->learn2learn==0.2.0->-r requirements.txt (line 4)) (1.7)\n",
            "Requirement already satisfied: fasteners>=0.14.1 in /usr/local/lib/python3.10/dist-packages (from gsutil->learn2learn==0.2.0->-r requirements.txt (line 4)) (0.19)\n",
            "Requirement already satisfied: gcs-oauth2-boto-plugin>=3.2 in /usr/local/lib/python3.10/dist-packages (from gsutil->learn2learn==0.2.0->-r requirements.txt (line 4)) (3.2)\n",
            "Requirement already satisfied: google-apitools>=0.5.32 in /usr/local/lib/python3.10/dist-packages (from gsutil->learn2learn==0.2.0->-r requirements.txt (line 4)) (0.5.32)\n",
            "Requirement already satisfied: httplib2==0.20.4 in /usr/local/lib/python3.10/dist-packages (from gsutil->learn2learn==0.2.0->-r requirements.txt (line 4)) (0.20.4)\n",
            "Requirement already satisfied: google-reauth>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from gsutil->learn2learn==0.2.0->-r requirements.txt (line 4)) (0.1.1)\n",
            "Requirement already satisfied: monotonic>=1.4 in /usr/local/lib/python3.10/dist-packages (from gsutil->learn2learn==0.2.0->-r requirements.txt (line 4)) (1.6)\n",
            "Requirement already satisfied: pyOpenSSL>=0.13 in /usr/local/lib/python3.10/dist-packages (from gsutil->learn2learn==0.2.0->-r requirements.txt (line 4)) (24.2.1)\n",
            "Requirement already satisfied: retry-decorator>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from gsutil->learn2learn==0.2.0->-r requirements.txt (line 4)) (1.1.1)\n",
            "Requirement already satisfied: six>=1.16.0 in /usr/local/lib/python3.10/dist-packages (from gsutil->learn2learn==0.2.0->-r requirements.txt (line 4)) (1.16.0)\n",
            "Requirement already satisfied: google-auth==2.17.0 in /usr/local/lib/python3.10/dist-packages (from google-auth[aiohttp]==2.17.0->gsutil->learn2learn==0.2.0->-r requirements.txt (line 4)) (2.17.0)\n",
            "Requirement already satisfied: google-auth-httplib2>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from gsutil->learn2learn==0.2.0->-r requirements.txt (line 4)) (0.2.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth==2.17.0->google-auth[aiohttp]==2.17.0->gsutil->learn2learn==0.2.0->-r requirements.txt (line 4)) (5.5.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth==2.17.0->google-auth[aiohttp]==2.17.0->gsutil->learn2learn==0.2.0->-r requirements.txt (line 4)) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth==2.17.0->google-auth[aiohttp]==2.17.0->gsutil->learn2learn==0.2.0->-r requirements.txt (line 4)) (4.7.2)\n",
            "Requirement already satisfied: aiohttp<4.0.0dev,>=3.6.2 in /usr/local/lib/python3.10/dist-packages (from google-auth[aiohttp]==2.17.0->gsutil->learn2learn==0.2.0->-r requirements.txt (line 4)) (3.10.10)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.10/dist-packages (from httplib2==0.20.4->gsutil->learn2learn==0.2.0->-r requirements.txt (line 4)) (3.2.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->learn2learn==0.2.0->-r requirements.txt (line 4)) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->learn2learn==0.2.0->-r requirements.txt (line 4)) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->learn2learn==0.2.0->-r requirements.txt (line 4)) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->learn2learn==0.2.0->-r requirements.txt (line 4)) (2024.8.30)\n",
            "Requirement already satisfied: osqp>=0.6.2 in /usr/local/lib/python3.10/dist-packages (from cvxpy>=1.1.0->qpth>=0.0.15->learn2learn==0.2.0->-r requirements.txt (line 4)) (0.6.7.post3)\n",
            "Requirement already satisfied: ecos>=2 in /usr/local/lib/python3.10/dist-packages (from cvxpy>=1.1.0->qpth>=0.0.15->learn2learn==0.2.0->-r requirements.txt (line 4)) (2.0.14)\n",
            "Requirement already satisfied: clarabel>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from cvxpy>=1.1.0->qpth>=0.0.15->learn2learn==0.2.0->-r requirements.txt (line 4)) (0.9.0)\n",
            "Requirement already satisfied: scs>=3.2.4.post1 in /usr/local/lib/python3.10/dist-packages (from cvxpy>=1.1.0->qpth>=0.0.15->learn2learn==0.2.0->-r requirements.txt (line 4)) (3.2.7)\n",
            "Requirement already satisfied: boto>=2.29.1 in /usr/local/lib/python3.10/dist-packages (from gcs-oauth2-boto-plugin>=3.2->gsutil->learn2learn==0.2.0->-r requirements.txt (line 4)) (2.49.0)\n",
            "Requirement already satisfied: oauth2client>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from gcs-oauth2-boto-plugin>=3.2->gsutil->learn2learn==0.2.0->-r requirements.txt (line 4)) (4.1.3)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.10/dist-packages (from rsa<5,>=3.1.4->google-auth==2.17.0->google-auth[aiohttp]==2.17.0->gsutil->learn2learn==0.2.0->-r requirements.txt (line 4)) (0.6.1)\n",
            "Requirement already satisfied: pyu2f in /usr/local/lib/python3.10/dist-packages (from google-reauth>=0.1.0->gsutil->learn2learn==0.2.0->-r requirements.txt (line 4)) (0.1.5)\n",
            "Requirement already satisfied: cryptography<44,>=41.0.5 in /usr/local/lib/python3.10/dist-packages (from pyOpenSSL>=0.13->gsutil->learn2learn==0.2.0->-r requirements.txt (line 4)) (43.0.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.1.0->learn2learn==0.2.0->-r requirements.txt (line 4)) (3.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0dev,>=3.6.2->google-auth[aiohttp]==2.17.0->gsutil->learn2learn==0.2.0->-r requirements.txt (line 4)) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0dev,>=3.6.2->google-auth[aiohttp]==2.17.0->gsutil->learn2learn==0.2.0->-r requirements.txt (line 4)) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0dev,>=3.6.2->google-auth[aiohttp]==2.17.0->gsutil->learn2learn==0.2.0->-r requirements.txt (line 4)) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0dev,>=3.6.2->google-auth[aiohttp]==2.17.0->gsutil->learn2learn==0.2.0->-r requirements.txt (line 4)) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0dev,>=3.6.2->google-auth[aiohttp]==2.17.0->gsutil->learn2learn==0.2.0->-r requirements.txt (line 4)) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0dev,>=3.6.2->google-auth[aiohttp]==2.17.0->gsutil->learn2learn==0.2.0->-r requirements.txt (line 4)) (1.17.0)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0dev,>=3.6.2->google-auth[aiohttp]==2.17.0->gsutil->learn2learn==0.2.0->-r requirements.txt (line 4)) (4.0.3)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.10/dist-packages (from cryptography<44,>=41.0.5->pyOpenSSL>=0.13->gsutil->learn2learn==0.2.0->-r requirements.txt (line 4)) (1.17.1)\n",
            "Requirement already satisfied: qdldl in /usr/local/lib/python3.10/dist-packages (from osqp>=0.6.2->cvxpy>=1.1.0->qpth>=0.0.15->learn2learn==0.2.0->-r requirements.txt (line 4)) (0.1.7.post4)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.12->cryptography<44,>=41.0.5->pyOpenSSL>=0.13->gsutil->learn2learn==0.2.0->-r requirements.txt (line 4)) (2.22)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.12.0->aiohttp<4.0.0dev,>=3.6.2->google-auth[aiohttp]==2.17.0->gsutil->learn2learn==0.2.0->-r requirements.txt (line 4)) (0.2.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- *If an error occurs, click ‘Run Session Again’ and then restart the runtime from the beginning.*"
      ],
      "metadata": {
        "id": "ryx2uX_0G3h6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3. Load Requirements and functions"
      ],
      "metadata": {
        "id": "Mm5Yl16mCUnA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os.path as osp\n",
        "from collections import OrderedDict\n",
        "import math\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import functional as F\n",
        "from torch.cuda.amp import GradScaler, autocast\n",
        "from PIL import Image\n",
        "import torchvision.transforms as transforms\n",
        "import torch\n",
        "from clip import clip\n",
        "from clip.simple_tokenizer import SimpleTokenizer as _Tokenizer\n",
        "import time\n",
        "from tqdm import tqdm\n",
        "import datetime\n",
        "import argparse\n",
        "from dassl.utils import setup_logger, set_random_seed, collect_env_info\n",
        "from dassl.config import get_cfg_default\n",
        "from dassl.engine import build_trainer\n",
        "from dassl.engine import TRAINER_REGISTRY, TrainerX\n",
        "from dassl.metrics import compute_accuracy\n",
        "from dassl.utils import load_pretrained_weights, load_checkpoint\n",
        "from dassl.optim import build_optimizer, build_lr_scheduler\n",
        "\n",
        "# custom\n",
        "import datasets.oxford_pets\n",
        "import datasets.oxford_flowers\n",
        "import datasets.fgvc_aircraft\n",
        "import datasets.dtd\n",
        "import datasets.eurosat\n",
        "import datasets.stanford_cars\n",
        "import datasets.food101\n",
        "import datasets.sun397\n",
        "import datasets.caltech101\n",
        "import datasets.ucf101\n",
        "import datasets.imagenet\n",
        "import datasets.imagenet_sketch\n",
        "import datasets.imagenetv2\n",
        "import datasets.imagenet_a\n",
        "import datasets.imagenet_r"
      ],
      "metadata": {
        "id": "Tck2BxWu17UB"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def print_args(args, cfg):\n",
        "    print(\"***************\")\n",
        "    print(\"** Arguments **\")\n",
        "    print(\"***************\")\n",
        "    optkeys = list(args.__dict__.keys())\n",
        "    optkeys.sort()\n",
        "    for key in optkeys:\n",
        "        print(\"{}: {}\".format(key, args.__dict__[key]))\n",
        "    print(\"************\")\n",
        "    print(\"** Config **\")\n",
        "    print(\"************\")\n",
        "    print(cfg)\n",
        "\n",
        "def reset_cfg(cfg, args):\n",
        "    if args.root:\n",
        "        cfg.DATASET.ROOT = args.root\n",
        "    if args.output_dir:\n",
        "        cfg.OUTPUT_DIR = args.output_dir\n",
        "    if args.seed:\n",
        "        cfg.SEED = args.seed\n",
        "    if args.trainer:\n",
        "        cfg.TRAINER.NAME = args.trainer\n",
        "    cfg.DATASET.NUM_SHOTS = 16\n",
        "    cfg.DATASET.SUBSAMPLE_CLASSES = args.subsample_classes\n",
        "    cfg.DATALOADER.TRAIN_X.BATCH_SIZE = args.train_batch_size\n",
        "    cfg.OPTIM.MAX_EPOCH = args.epoch\n",
        "\n",
        "def extend_cfg(cfg):\n",
        "    \"\"\"\n",
        "    Add new config variables.\n",
        "    \"\"\"\n",
        "    from yacs.config import CfgNode as CN\n",
        "    cfg.TRAINER.COOP = CN()\n",
        "    cfg.TRAINER.COOP.N_CTX = 16  # number of context vectors\n",
        "    cfg.TRAINER.COOP.CSC = False  # class-specific context\n",
        "    cfg.TRAINER.COOP.CTX_INIT = \"\"  # initialization words\n",
        "    cfg.TRAINER.COOP.PREC = \"fp16\"  # fp16, fp32, amp\n",
        "    cfg.TRAINER.COOP.CLASS_TOKEN_POSITION = \"end\"  # 'middle' or 'end' or 'front'\n",
        "    cfg.TRAINER.COCOOP = CN()\n",
        "    cfg.TRAINER.COCOOP.N_CTX = 4  # number of context vectors\n",
        "    cfg.TRAINER.COCOOP.CTX_INIT = \"a photo of a\"  # initialization words\n",
        "    cfg.TRAINER.COCOOP.PREC = \"fp16\"  # fp16, fp32, amp\n",
        "    cfg.TRAINER.PROMETAR = CN()\n",
        "    cfg.TRAINER.PROMETAR.N_CTX_VISION = 4  # number of context vectors at the vision branch\n",
        "    cfg.TRAINER.PROMETAR.N_CTX_TEXT = 4  # number of context vectors at the language branch\n",
        "    cfg.TRAINER.PROMETAR.CTX_INIT = \"a photo of a\"  # initialization words\n",
        "    cfg.TRAINER.PROMETAR.PREC = \"fp16\"  # fp16, fp32, amp\n",
        "    cfg.TRAINER.PROMETAR.PROMPT_DEPTH_VISION = 9  # Max 12, minimum 0, for 0 it will be using shallow IVLP prompting (J=1)\n",
        "    cfg.TRAINER.PROMETAR.PROMPT_DEPTH_TEXT = 9  # Max 12, minimum 0, for 0 it will be using shallow IVLP prompting (J=1)\n",
        "    cfg.DATASET.SUBSAMPLE_CLASSES = \"all\"  # all, base or new\n",
        "    cfg.TRAINER.PROMETAR.ADAPT_LR = 0.0005\n",
        "    cfg.TRAINER.PROMETAR.LR_RATIO = 0.0005\n",
        "    cfg.TRAINER.PROMETAR.FAST_ADAPTATION = False\n",
        "    cfg.TRAINER.PROMETAR.MIXUP_ALPHA = 0.5\n",
        "    cfg.TRAINER.PROMETAR.MIXUP_BETA = 0.5\n",
        "    cfg.TRAINER.PROMETAR.DIM_RATE=8\n",
        "    cfg.OPTIM_VNET = CN()\n",
        "    cfg.OPTIM_VNET.NAME = \"adam\"\n",
        "    cfg.OPTIM_VNET.LR = 0.0003\n",
        "    cfg.OPTIM_VNET.WEIGHT_DECAY = 5e-4\n",
        "    cfg.OPTIM_VNET.MOMENTUM = 0.9\n",
        "    cfg.OPTIM_VNET.SGD_DAMPNING = 0\n",
        "    cfg.OPTIM_VNET.SGD_NESTEROV = False\n",
        "    cfg.OPTIM_VNET.RMSPROP_ALPHA = 0.99\n",
        "    cfg.OPTIM_VNET.ADAM_BETA1 = 0.9\n",
        "    cfg.OPTIM_VNET.ADAM_BETA2 = 0.999\n",
        "    cfg.OPTIM_VNET.STAGED_LR = False\n",
        "    cfg.OPTIM_VNET.NEW_LAYERS = ()\n",
        "    cfg.OPTIM_VNET.BASE_LR_MULT = 0.1\n",
        "    # Learning rate scheduler\n",
        "    cfg.OPTIM_VNET.LR_SCHEDULER = \"single_step\"\n",
        "    # -1 or 0 means the stepsize is equal to max_epoch\n",
        "    cfg.OPTIM_VNET.STEPSIZE = (-1, )\n",
        "    cfg.OPTIM_VNET.GAMMA = 0.1\n",
        "    cfg.OPTIM_VNET.MAX_EPOCH = 10\n",
        "    # Set WARMUP_EPOCH larger than 0 to activate warmup training\n",
        "    cfg.OPTIM_VNET.WARMUP_EPOCH = -1\n",
        "    # Either linear or constant\n",
        "    cfg.OPTIM_VNET.WARMUP_TYPE = \"linear\"\n",
        "    # Constant learning rate when type=constant\n",
        "    cfg.OPTIM_VNET.WARMUP_CONS_LR = 1e-5\n",
        "    # Minimum learning rate when type=linear\n",
        "    cfg.OPTIM_VNET.WARMUP_MIN_LR = 1e-5\n",
        "    # Recount epoch for the next scheduler (last_epoch=-1)\n",
        "    # Otherwise last_epoch=warmup_epoch\n",
        "    cfg.OPTIM_VNET.WARMUP_RECOUNT = True\n",
        "\n",
        "def setup_cfg(args):\n",
        "    cfg = get_cfg_default()\n",
        "    extend_cfg(cfg)\n",
        "    # 1. From the dataset config file\n",
        "    if args.dataset_config_file:\n",
        "        cfg.merge_from_file(args.dataset_config_file)\n",
        "    # 2. From the method config file\n",
        "    if args.config_file:\n",
        "        cfg.merge_from_file(args.config_file)\n",
        "    # 3. From input arguments\n",
        "    reset_cfg(cfg, args)\n",
        "    cfg.freeze()\n",
        "    return cfg"
      ],
      "metadata": {
        "id": "H_jVzJWQChw9"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3. Download EuroSAT dataset"
      ],
      "metadata": {
        "id": "2quBDo0n31-0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%mkdir outputs\n",
        "%mkdir data\n",
        "\n",
        "%cd data\n",
        "%mkdir eurosat\n",
        "!wget http://madm.dfki.de/files/sentinel/EuroSAT.zip EuroSAT.zip\n",
        "\n",
        "!unzip -o EuroSAT.zip -d eurosat/\n",
        "%cd eurosat\n",
        "!gdown 1Ip7yaCWFi0eaOFUGga0lUdVi_DDQth1o\n",
        "\n",
        "%cd ../../\n"
      ],
      "metadata": {
        "id": "Rq87rDm-kTjY",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The structure of the data folder inside the ProMetaR folder should be as follows:\n",
        "\n",
        "\t•\teurosat/2750\n",
        "\t•\teurosat/split_zhou_EuroSAT.json"
      ],
      "metadata": {
        "id": "9xps7PVzG6qk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "ASnsQA9hzahu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# [2] Load pre-trained CLIP Model"
      ],
      "metadata": {
        "id": "OOUyP2s2dDXQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "_tokenizer = _Tokenizer()\n",
        "\n",
        "def load_clip_to_cpu(cfg): # Load CLIP\n",
        "    backbone_name = cfg.MODEL.BACKBONE.NAME\n",
        "    url = clip._MODELS[backbone_name]\n",
        "    model_path = clip._download(url)\n",
        "\n",
        "    try:\n",
        "        # loading JIT archive\n",
        "        model = torch.jit.load(model_path, map_location=\"cpu\").eval()\n",
        "        state_dict = None\n",
        "\n",
        "    except RuntimeError:\n",
        "        state_dict = torch.load(model_path, map_location=\"cpu\")\n",
        "\n",
        "    if cfg.TRAINER.NAME == \"\":\n",
        "      design_trainer = \"CoOp\"\n",
        "    else:\n",
        "      design_trainer = cfg.TRAINER.NAME\n",
        "    design_details = {\"trainer\": design_trainer,\n",
        "                      \"vision_depth\": 0,\n",
        "                      \"language_depth\": 0, \"vision_ctx\": 0,\n",
        "                      \"language_ctx\": 0}\n",
        "    model = clip.build_model(state_dict or model.state_dict(), design_details)\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "mZlULoCU1j0j"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from dassl.config import get_cfg_default\n",
        "cfg = get_cfg_default()\n",
        "cfg.MODEL.BACKBONE.NAME = \"ViT-B/16\" # Set the vision encoder backbone of CLIP to ViT.\n",
        "clip_model = load_clip_to_cpu(cfg)"
      ],
      "metadata": {
        "id": "KiyjkEkcXPyR"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Check CLIP model"
      ],
      "metadata": {
        "id": "NH3Ehw3xNtZy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(clip_model)"
      ],
      "metadata": {
        "id": "vYuHDRDwNxe7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# [3] CoOpCLIP Implementation\n",
        "\n",
        "CoOpCLIP is composed of pre-trained CLIP Text encoder, pre-trained CLIP Image encoder, and learnable prompt."
      ],
      "metadata": {
        "id": "VgsA4RzQ8yCr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Make Module 1: CLIP Text Encoder\n",
        "\n",
        "**Input**\n",
        "- token prefix (SOS token) + learnable prompt + class label + token suffix (CLS token)\n",
        "\n",
        "**Output**\n",
        "- text feature of input prompts"
      ],
      "metadata": {
        "id": "kQY1UE9S1pcx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TextEncoder(nn.Module):\n",
        "    def __init__(self, clip_model):\n",
        "        super().__init__()\n",
        "        self.transformer = clip_model.transformer\n",
        "        self.positional_embedding = clip_model.positional_embedding\n",
        "        self.ln_final = clip_model.ln_final\n",
        "        self.text_projection = clip_model.text_projection\n",
        "        self.dtype = clip_model.dtype\n",
        "\n",
        "    def forward(self, prompts, tokenized_prompts): # Call model forward\n",
        "        x = prompts + self.positional_embedding.type(self.dtype)\n",
        "        x = x.permute(1, 0, 2)  # NLD -> LND\n",
        "        x = self.transformer(x)\n",
        "        x = x.permute(1, 0, 2)  # LND -> NLD\n",
        "        x = self.ln_final(x).type(self.dtype)\n",
        "        x = x[torch.arange(x.shape[0]), tokenized_prompts.argmax(dim=-1)] @ self.text_projection\n",
        "        return x"
      ],
      "metadata": {
        "id": "PPzA8a1n1oaR"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Make Module 2: CLIP Image Encoder\n",
        "\n",
        "**Input**\n",
        "- image\n",
        "\n",
        "**Output**\n",
        "- image feature"
      ],
      "metadata": {
        "id": "Q17p2MV42W8d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(clip_model.visual)"
      ],
      "metadata": {
        "id": "DAZ0nR2X2WM2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Make Module 3: Learnable Prompt\n",
        "\n",
        "**Output**\n",
        "- Learnable prompt"
      ],
      "metadata": {
        "id": "NVL_tLqM2ELT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CoOpPromptLearner(nn.Module):\n",
        "    def __init__(self, cfg, classnames, clip_model):\n",
        "        super().__init__()\n",
        "        n_cls = len(classnames)\n",
        "        n_ctx = cfg.TRAINER.COOP.N_CTX\n",
        "        ctx_init = cfg.TRAINER.COOP.CTX_INIT\n",
        "        dtype = clip_model.dtype\n",
        "        ctx_dim = clip_model.ln_final.weight.shape[0]\n",
        "        clip_imsize = clip_model.visual.input_resolution\n",
        "        cfg_imsize = cfg.INPUT.SIZE[0]\n",
        "        assert cfg_imsize == clip_imsize, f\"cfg_imsize ({cfg_imsize}) must equal to clip_imsize ({clip_imsize})\"\n",
        "\n",
        "        ### Learnable Prompts Initialization ###\n",
        "        if ctx_init:\n",
        "            # use given words to initialize context vectors\n",
        "            ctx_init = ctx_init.replace(\"_\", \" \")\n",
        "            n_ctx = len(ctx_init.split(\" \"))\n",
        "            prompt = clip.tokenize(ctx_init)\n",
        "            with torch.no_grad():\n",
        "                embedding = clip_model.token_embedding(prompt).type(dtype)\n",
        "            ctx_vectors = embedding[0, 1 : 1 + n_ctx, :]\n",
        "            prompt_prefix = ctx_init\n",
        "        else:\n",
        "            # random initialization\n",
        "            if cfg.TRAINER.COOP.CSC:\n",
        "                print(\"Initializing class-specific contexts\")\n",
        "                ctx_vectors = torch.empty(n_cls, n_ctx, ctx_dim, dtype=dtype)\n",
        "            else:\n",
        "                print(\"Initializing a generic context\")\n",
        "                ctx_vectors = torch.empty(n_ctx, ctx_dim, dtype=dtype)\n",
        "            nn.init.normal_(ctx_vectors, std=0.02)\n",
        "            prompt_prefix = \" \".join([\"X\"] * n_ctx)\n",
        "        ######################################################\n",
        "        print(f'Initial context: \"{prompt_prefix}\"')\n",
        "        print(f\"Number of context words (tokens): {n_ctx}\")\n",
        "        self.ctx = nn.Parameter(ctx_vectors)  # Wrap the initialized prompts above as parameters to make them trainable.\n",
        "\n",
        "        ### Tokenize ###\n",
        "        classnames = [name.replace(\"_\", \" \") for name in classnames]  # 예) \"Forest\"\n",
        "        name_lens = [len(_tokenizer.encode(name)) for name in classnames]\n",
        "        prompts = [prompt_prefix + \" \" + name + \".\" for name in classnames] # 예) \"A photo of Forest.\"\n",
        "        tokenized_prompts = torch.cat([clip.tokenize(p) for p in prompts]) # 예) [49406, 320, 1125, 539...]\n",
        "        ################\n",
        "\n",
        "        with torch.no_grad():\n",
        "            embedding = clip_model.token_embedding(tokenized_prompts).type(dtype)\n",
        "        # These token vectors will be saved when in save_model(),\n",
        "        # but they should be ignored in load_model() as we want to use\n",
        "        # those computed using the current class names\n",
        "        self.register_buffer(\"token_prefix\", embedding[:, :1, :])  # SOS (문장의 시작을 알려주는 토큰)\n",
        "        self.register_buffer(\"token_suffix\", embedding[:, 1 + n_ctx :, :])  # CLS, EOS (문장의 끝을 알려주는 토큰)\n",
        "        self.n_cls = n_cls\n",
        "        self.n_ctx = n_ctx\n",
        "        self.tokenized_prompts = tokenized_prompts  # torch.Tensor\n",
        "        self.name_lens = name_lens\n",
        "\n",
        "    def construct_prompts(self, ctx, prefix, suffix, label=None):\n",
        "        # dim0 is either batch_size (during training) or n_cls (during testing)\n",
        "        # ctx: context tokens, with shape of (dim0, n_ctx, ctx_dim)\n",
        "        # prefix: the sos token, with shape of (n_cls, 1, ctx_dim)\n",
        "        # suffix: remaining tokens, with shape of (n_cls, *, ctx_dim)\n",
        "        if label is not None:\n",
        "            prefix = prefix[label]\n",
        "            suffix = suffix[label]\n",
        "        prompts = torch.cat(\n",
        "            [\n",
        "                prefix,  # (dim0, 1, dim)\n",
        "                ctx,  # (dim0, n_ctx, dim)\n",
        "                suffix,  # (dim0, *, dim)\n",
        "            ],\n",
        "            dim=1,\n",
        "        )\n",
        "        return prompts\n",
        "\n",
        "    def forward(self):\n",
        "        ctx = self.ctx\n",
        "        if ctx.dim() == 2:\n",
        "            ctx = ctx.unsqueeze(0).expand(self.n_cls, -1, -1)\n",
        "        prefix = self.token_prefix\n",
        "        suffix = self.token_suffix\n",
        "        prompts = self.construct_prompts(ctx, prefix, suffix) #[시작토큰, Input prompts,끝 토큰]\n",
        "        return prompts"
      ],
      "metadata": {
        "id": "3_YQTO0Y2R1C"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Make CoOpCLIP (Module1 + Module2 + Module3)\n",
        "\n",
        "**Input**\n",
        "- Image\n",
        "\n",
        "**Output**\n",
        "- Logit\n",
        "\n",
        "**How to compute logit?**\n",
        "- image_features : Image representation $\\mathbf{f}$\n",
        "- text_features : Text representation $g\\left(\\mathbf{t}_i\\right)$\n",
        "- Logit:\n",
        "$p\\left(y=i | \\mathbf{x} \\right) = \\frac{\\exp \\left(\\cos\\left(g\\left(\\mathbf{t}_i\\right),\\mathbf{f} \\right)/\\tau \\right)}{\\sum_{j=1}^K \\exp \\left(\\cos\\left(g\\left(\\mathbf{t}_j\\right),\\mathbf{f} \\right)/\\tau \\right)} $"
      ],
      "metadata": {
        "id": "Howh4jCR-Mst"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CoOpCustomCLIP(nn.Module):\n",
        "    def __init__(self, cfg, classnames, clip_model):\n",
        "        super().__init__()\n",
        "        self.prompt_learner = CoOpPromptLearner(cfg, classnames, clip_model)\n",
        "        self.tokenized_prompts = self.prompt_learner.tokenized_prompts\n",
        "        self.image_encoder = clip_model.visual\n",
        "        self.text_encoder = TextEncoder(clip_model)\n",
        "        self.logit_scale = clip_model.logit_scale\n",
        "        self.dtype = clip_model.dtype\n",
        "\n",
        "    def forward(self, image):\n",
        "        image_features = self.image_encoder(image.type(self.dtype))\n",
        "\n",
        "        prompts = self.prompt_learner()\n",
        "        tokenized_prompts = self.tokenized_prompts\n",
        "        text_features = self.text_encoder(prompts, tokenized_prompts)\n",
        "\n",
        "        image_features = image_features / image_features.norm(dim=-1, keepdim=True)\n",
        "        text_features = text_features / text_features.norm(dim=-1, keepdim=True)\n",
        "\n",
        "        logit_scale = self.logit_scale.exp()\n",
        "        logits = logit_scale * image_features @ text_features.t()\n",
        "\n",
        "        return logits"
      ],
      "metadata": {
        "id": "qHIcuAkF-VHX"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# [4] CoOpCLIP Training"
      ],
      "metadata": {
        "id": "95g7yRCT4brR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Training configurations"
      ],
      "metadata": {
        "id": "mXo4-zJJDOYf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "parser = argparse.ArgumentParser()\n",
        "parser.add_argument(\"--root\", type=str, default=\"data/\", help=\"path to dataset\")\n",
        "parser.add_argument(\"--output-dir\", type=str, default=\"outputs/cocoop3\", help=\"output directory\")\n",
        "parser.add_argument(\n",
        "    \"--seed\", type=int, default=1, help=\"only positive value enables a fixed seed\"\n",
        ")\n",
        "parser.add_argument(\n",
        "    \"--config-file\", type=str, default=\"configs/trainers/ProMetaR/vit_b16_c2_ep10_batch4_4+4ctx.yaml\", help=\"path to config file\"\n",
        ")\n",
        "parser.add_argument(\n",
        "    \"--dataset-config-file\",\n",
        "    type=str,\n",
        "    default=\"configs/datasets/eurosat.yaml\",\n",
        "    help=\"path to config file for dataset setup\",\n",
        ")\n",
        "parser.add_argument(\"--trainer\", type=str, default=\"CoOp\", help=\"name of trainer\")\n",
        "parser.add_argument(\"--eval-only\", action=\"store_true\", help=\"evaluation only\")\n",
        "parser.add_argument(\n",
        "    \"--model-dir\",\n",
        "    type=str,\n",
        "    default=\"\",\n",
        "    help=\"load model from this directory for eval-only mode\",\n",
        ")\n",
        "parser.add_argument(\"--train-batch-size\", type=int, default=4)\n",
        "parser.add_argument(\"--epoch\", type=int, default=10)\n",
        "parser.add_argument(\"--subsample-classes\", type=str, default=\"base\")\n",
        "parser.add_argument(\n",
        "    \"--load-epoch\", type=int, default=0, help=\"load model weights at this epoch for evaluation\"\n",
        ")\n",
        "args = parser.parse_args([])"
      ],
      "metadata": {
        "id": "ZcNsq17FDRzk"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Trainer Class"
      ],
      "metadata": {
        "id": "yB0_2nm0C73P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@TRAINER_REGISTRY.register(force=True)\n",
        "class CoOp(TrainerX):\n",
        "    \"\"\"Context Optimization (CoOp).\n",
        "\n",
        "    Learning to Prompt for Vision-Language Models\n",
        "    https://arxiv.org/abs/2109.01134\n",
        "    \"\"\"\n",
        "\n",
        "    def check_cfg(self, cfg):\n",
        "        assert cfg.TRAINER.COOP.PREC in [\"fp16\", \"fp32\", \"amp\"]\n",
        "\n",
        "    def build_model(self):\n",
        "        cfg = self.cfg\n",
        "        classnames = self.dm.dataset.classnames\n",
        "\n",
        "        print(f\"Loading CLIP (backbone: {cfg.MODEL.BACKBONE.NAME})\")\n",
        "        clip_model = load_clip_to_cpu(cfg)\n",
        "\n",
        "        if cfg.TRAINER.COOP.PREC == \"fp32\" or cfg.TRAINER.COOP.PREC == \"amp\":\n",
        "            # CLIP's default precision is fp16\n",
        "            clip_model.float()\n",
        "\n",
        "        print(\"Building custom CLIP\")\n",
        "        self.model = CoOpCustomCLIP(cfg, classnames, clip_model)\n",
        "\n",
        "        print(\"Turning off gradients in both the image and the text encoder\")\n",
        "        for name, param in self.model.named_parameters():\n",
        "            if \"prompt_learner\" not in name:\n",
        "                param.requires_grad_(False)\n",
        "\n",
        "        if cfg.MODEL.INIT_WEIGHTS:\n",
        "            load_pretrained_weights(self.model.prompt_learner, cfg.MODEL.INIT_WEIGHTS)\n",
        "\n",
        "        self.model.to(self.device)\n",
        "        # NOTE: only give prompt_learner to the optimizer\n",
        "        self.optim = build_optimizer(self.model.prompt_learner, cfg.OPTIM)\n",
        "        self.sched = build_lr_scheduler(self.optim, cfg.OPTIM)\n",
        "        self.register_model(\"prompt_learner\", self.model.prompt_learner, self.optim, self.sched)\n",
        "\n",
        "        self.scaler = GradScaler() if cfg.TRAINER.COOP.PREC == \"amp\" else None\n",
        "\n",
        "        # Note that multi-gpu training could be slow because CLIP's size is\n",
        "        # big, which slows down the copy operation in DataParallel\n",
        "        device_count = torch.cuda.device_count()\n",
        "        if device_count > 1:\n",
        "            print(f\"Multiple GPUs detected (n_gpus={device_count}), use all of them!\")\n",
        "            self.model = nn.DataParallel(self.model)\n",
        "\n",
        "    def before_train(self):\n",
        "        directory = self.cfg.OUTPUT_DIR\n",
        "        if self.cfg.RESUME:\n",
        "            directory = self.cfg.RESUME\n",
        "        self.start_epoch = self.resume_model_if_exist(directory)\n",
        "\n",
        "        # Remember the starting time (for computing the elapsed time)\n",
        "        self.time_start = time.time()\n",
        "\n",
        "    def forward_backward(self, batch):\n",
        "        image, label = self.parse_batch_train(batch)\n",
        "\n",
        "        prec = self.cfg.TRAINER.COOP.PREC\n",
        "        output = self.model(image)      # Input image 모델 통과\n",
        "        loss = F.cross_entropy(output, label)  # Loss 선언\n",
        "        self.model_backward_and_update(loss)  # Backward 및 모델 parameter 업데이트\n",
        "\n",
        "        loss_summary = {\n",
        "            \"loss\": loss.item(),\n",
        "            \"acc\": compute_accuracy(output, label)[0].item(),\n",
        "        }\n",
        "\n",
        "        if (self.batch_idx + 1) == self.num_batches:\n",
        "            self.update_lr()\n",
        "\n",
        "        return loss_summary\n",
        "\n",
        "    def parse_batch_train(self, batch):\n",
        "        input = batch[\"img\"]\n",
        "        label = batch[\"label\"]\n",
        "        input = input.to(self.device)\n",
        "        label = label.to(self.device)\n",
        "        return input, label\n",
        "\n",
        "    def load_model(self, directory, epoch=None):\n",
        "        if not directory:\n",
        "            print(\"Note that load_model() is skipped as no pretrained model is given\")\n",
        "            return\n",
        "\n",
        "        names = self.get_model_names()\n",
        "\n",
        "        # By default, the best model is loaded\n",
        "        model_file = \"model-best.pth.tar\"\n",
        "\n",
        "        if epoch is not None:\n",
        "            model_file = \"model.pth.tar-\" + str(epoch)\n",
        "\n",
        "        for name in names:\n",
        "            model_path = osp.join(directory, name, model_file)\n",
        "\n",
        "            if not osp.exists(model_path):\n",
        "                raise FileNotFoundError('Model not found at \"{}\"'.format(model_path))\n",
        "\n",
        "            checkpoint = load_checkpoint(model_path)\n",
        "            state_dict = checkpoint[\"state_dict\"]\n",
        "            epoch = checkpoint[\"epoch\"]\n",
        "\n",
        "            # Ignore fixed token vectors\n",
        "            if \"token_prefix\" in state_dict:\n",
        "                del state_dict[\"token_prefix\"]\n",
        "\n",
        "            if \"token_suffix\" in state_dict:\n",
        "                del state_dict[\"token_suffix\"]\n",
        "\n",
        "            print(\"Loading weights to {} \" 'from \"{}\" (epoch = {})'.format(name, model_path, epoch))\n",
        "            # set strict=False\n",
        "            self._models[name].load_state_dict(state_dict, strict=False)\n",
        "\n",
        "    def after_train(self):\n",
        "      print(\"Finish training\")\n",
        "\n",
        "      do_test = not self.cfg.TEST.NO_TEST\n",
        "      if do_test:\n",
        "          if self.cfg.TEST.FINAL_MODEL == \"best_val\":\n",
        "              print(\"Deploy the model with the best val performance\")\n",
        "              self.load_model(self.output_dir)\n",
        "          else:\n",
        "              print(\"Deploy the last-epoch model\")\n",
        "          acc = self.test()\n",
        "\n",
        "      # Show elapsed time\n",
        "      elapsed = round(time.time() - self.time_start)\n",
        "      elapsed = str(datetime.timedelta(seconds=elapsed))\n",
        "      print(f\"Elapsed: {elapsed}\")\n",
        "\n",
        "      # Close writer\n",
        "      self.close_writer()\n",
        "      return acc\n",
        "\n",
        "    def train(self):\n",
        "        \"\"\"Generic training loops.\"\"\"\n",
        "        self.before_train()\n",
        "        for self.epoch in range(self.start_epoch, self.max_epoch):\n",
        "            self.before_epoch()\n",
        "            self.run_epoch()\n",
        "            self.after_epoch()\n",
        "        acc = self.after_train()\n",
        "        return acc\n"
      ],
      "metadata": {
        "id": "ueUiBs_AzMMs"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main(args):\n",
        "    cfg = setup_cfg(args)\n",
        "    if cfg.SEED >= 0:\n",
        "        set_random_seed(cfg.SEED)\n",
        "\n",
        "    if torch.cuda.is_available() and cfg.USE_CUDA:\n",
        "        torch.backends.cudnn.benchmark = True\n",
        "\n",
        "    trainer = build_trainer(cfg)\n",
        "    if args.eval_only:\n",
        "        trainer.load_model(args.model_dir, epoch=args.load_epoch)\n",
        "        acc = trainer.test()\n",
        "        return acc\n",
        "\n",
        "    acc = trainer.train()\n",
        "    return acc"
      ],
      "metadata": {
        "id": "5JvkxdV4zKjM"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training CoOpCLIP on Base Class\n",
        "- The **Base class** refers to classes that were seen during training.\n",
        "- In contrast, the **New class** refers to classes that were not seen during training."
      ],
      "metadata": {
        "id": "Z51vi3Ws_hFl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "args.trainer = \"CoOp\"\n",
        "args.train_batch_size = 4\n",
        "args.epoch = 100\n",
        "args.output_dir = \"outputs/coop\"\n",
        "\n",
        "# Train on the Base Classes Train split and evaluate accuracy on the Base Classes Test split.\n",
        "args.subsample_classes = \"base\"\n",
        "coop_base_acc = main(args)"
      ],
      "metadata": {
        "id": "9M4KiMVlmrM8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "67b17e0a-4a0b-4982-997d-c749319996f3"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading trainer: CoOp\n",
            "Loading dataset: EuroSAT\n",
            "Reading split from /content/ProMetaR/data/eurosat/split_zhou_EuroSAT.json\n",
            "Loading preprocessed few-shot data from /content/ProMetaR/data/eurosat/split_fewshot/shot_16-seed_1.pkl\n",
            "SUBSAMPLE BASE CLASSES!\n",
            "Building transform_train\n",
            "+ random resized crop (size=(224, 224), scale=(0.08, 1.0))\n",
            "+ random flip\n",
            "+ to torch tensor of range [0, 1]\n",
            "+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])\n",
            "Building transform_test\n",
            "+ resize the smaller edge to 224\n",
            "+ 224x224 center crop\n",
            "+ to torch tensor of range [0, 1]\n",
            "+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])\n",
            "---------  -------\n",
            "Dataset    EuroSAT\n",
            "# classes  5\n",
            "# train_x  80\n",
            "# val      20\n",
            "# test     4,200\n",
            "---------  -------\n",
            "Loading CLIP (backbone: ViT-B/16)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
            "  warnings.warn(\n",
            "/content/ProMetaR/dassl/utils/torchtools.py:102: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(fpath, map_location=map_location)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Building custom CLIP\n",
            "Initializing a generic context\n",
            "Initial context: \"X X X X X X X X X X X X X X X X\"\n",
            "Number of context words (tokens): 16\n",
            "Turning off gradients in both the image and the text encoder\n",
            "Loading evaluator: Classification\n",
            "Loading weights to prompt_learner from \"outputs/coop/prompt_learner/model.pth.tar-100\" (epoch = 100)\n",
            "Evaluate on the *test* set\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/42 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  2%|▏         | 1/42 [00:03<02:42,  3.97s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  5%|▍         | 2/42 [00:04<01:13,  1.84s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  7%|▋         | 3/42 [00:04<00:45,  1.15s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 10%|▉         | 4/42 [00:05<00:32,  1.18it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 12%|█▏        | 5/42 [00:05<00:24,  1.50it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 14%|█▍        | 6/42 [00:05<00:20,  1.79it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 17%|█▋        | 7/42 [00:06<00:17,  2.04it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 19%|█▉        | 8/42 [00:06<00:15,  2.24it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 21%|██▏       | 9/42 [00:06<00:13,  2.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 24%|██▍       | 10/42 [00:07<00:12,  2.53it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 26%|██▌       | 11/42 [00:07<00:11,  2.62it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 29%|██▊       | 12/42 [00:07<00:11,  2.72it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 31%|███       | 13/42 [00:08<00:10,  2.76it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 33%|███▎      | 14/42 [00:08<00:10,  2.75it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 36%|███▌      | 15/42 [00:08<00:09,  2.81it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 38%|███▊      | 16/42 [00:09<00:09,  2.80it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 40%|████      | 17/42 [00:09<00:09,  2.77it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 43%|████▎     | 18/42 [00:09<00:08,  2.74it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
            "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
            "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
            "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
            "        2, 2, 2, 2], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 45%|████▌     | 19/42 [00:10<00:08,  2.66it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
            "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
            "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
            "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
            "        2, 2, 2, 2], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 48%|████▊     | 20/42 [00:10<00:08,  2.72it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
            "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
            "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
            "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
            "        2, 2, 2, 2], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 50%|█████     | 21/42 [00:11<00:07,  2.70it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
            "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
            "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
            "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
            "        2, 2, 2, 2], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 52%|█████▏    | 22/42 [00:11<00:07,  2.68it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
            "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
            "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
            "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
            "        2, 2, 2, 2], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 55%|█████▍    | 23/42 [00:11<00:07,  2.68it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
            "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
            "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
            "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
            "        2, 2, 2, 2], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 57%|█████▋    | 24/42 [00:12<00:06,  2.66it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
            "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
            "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
            "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
            "        2, 2, 2, 2], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 60%|█████▉    | 25/42 [00:12<00:06,  2.66it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
            "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
            "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
            "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
            "        2, 2, 2, 2], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 62%|██████▏   | 26/42 [00:12<00:05,  2.68it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
            "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
            "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
            "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
            "        2, 2, 2, 2], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 64%|██████▍   | 27/42 [00:13<00:05,  2.63it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
            "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
            "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
            "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
            "        3, 3, 3, 3], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 67%|██████▋   | 28/42 [00:13<00:05,  2.61it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
            "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
            "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
            "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
            "        3, 3, 3, 3], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 69%|██████▉   | 29/42 [00:14<00:04,  2.65it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
            "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
            "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
            "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
            "        3, 3, 3, 3], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 71%|███████▏  | 30/42 [00:14<00:04,  2.66it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
            "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
            "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
            "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
            "        3, 3, 3, 3], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 74%|███████▍  | 31/42 [00:14<00:04,  2.68it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
            "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
            "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
            "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
            "        3, 3, 3, 3], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 76%|███████▌  | 32/42 [00:15<00:03,  2.73it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
            "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
            "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
            "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
            "        3, 3, 3, 3], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 79%|███████▊  | 33/42 [00:15<00:03,  2.72it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
            "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
            "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
            "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
            "        3, 3, 3, 3], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 81%|████████  | 34/42 [00:15<00:02,  2.76it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
            "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
            "        3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
            "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
            "        4, 4, 4, 4], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 83%|████████▎ | 35/42 [00:16<00:02,  2.79it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
            "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
            "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
            "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
            "        4, 4, 4, 4], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 86%|████████▌ | 36/42 [00:16<00:02,  2.78it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
            "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
            "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
            "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
            "        4, 4, 4, 4], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 88%|████████▊ | 37/42 [00:16<00:01,  2.80it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
            "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
            "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
            "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
            "        4, 4, 4, 4], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 90%|█████████ | 38/42 [00:17<00:01,  2.81it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
            "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
            "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
            "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
            "        4, 4, 4, 4], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 93%|█████████▎| 39/42 [00:17<00:01,  2.78it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
            "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
            "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
            "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
            "        4, 4, 4, 4], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 95%|█████████▌| 40/42 [00:18<00:00,  2.80it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
            "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
            "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
            "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
            "        4, 4, 4, 4], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 98%|█████████▊| 41/42 [00:18<00:00,  2.80it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
            "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
            "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
            "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
            "        4, 4, 4, 4], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 42/42 [00:19<00:00,  2.18it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=> result\n",
            "* total: 4,200\n",
            "* correct: 3,839\n",
            "* accuracy: 91.4%\n",
            "* error: 8.6%\n",
            "* macro_f1: 91.5%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluate CoOpCLIP on New Class"
      ],
      "metadata": {
        "id": "yETA2Zp6Expc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# New Classes 에 대한 Acc\n",
        "args.model_dir = \"outputs/coop\"\n",
        "args.output_dir = \"outputs/coop/new_classes\"\n",
        "args.subsample_classes = \"new\"\n",
        "args.load_epoch = 100\n",
        "args.eval_only = True\n",
        "coop_novel_acc = main(args)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LB6gek8o_zQv",
        "outputId": "c0a44431-32ed-46b5-bc08-010087a50bb3"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading trainer: CoOp\n",
            "Loading dataset: EuroSAT\n",
            "Reading split from /content/ProMetaR/data/eurosat/split_zhou_EuroSAT.json\n",
            "Loading preprocessed few-shot data from /content/ProMetaR/data/eurosat/split_fewshot/shot_16-seed_1.pkl\n",
            "SUBSAMPLE NEW CLASSES!\n",
            "Building transform_train\n",
            "+ random resized crop (size=(224, 224), scale=(0.08, 1.0))\n",
            "+ random flip\n",
            "+ to torch tensor of range [0, 1]\n",
            "+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])\n",
            "Building transform_test\n",
            "+ resize the smaller edge to 224\n",
            "+ 224x224 center crop\n",
            "+ to torch tensor of range [0, 1]\n",
            "+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])\n",
            "---------  -------\n",
            "Dataset    EuroSAT\n",
            "# classes  5\n",
            "# train_x  80\n",
            "# val      20\n",
            "# test     3,900\n",
            "---------  -------\n",
            "Loading CLIP (backbone: ViT-B/16)\n",
            "Building custom CLIP\n",
            "Initializing a generic context\n",
            "Initial context: \"X X X X X X X X X X X X X X X X\"\n",
            "Number of context words (tokens): 16\n",
            "Turning off gradients in both the image and the text encoder\n",
            "Loading evaluator: Classification\n",
            "Loading weights to prompt_learner from \"outputs/coop/prompt_learner/model.pth.tar-100\" (epoch = 100)\n",
            "Evaluate on the *test* set\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/39 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  3%|▎         | 1/39 [00:03<02:29,  3.93s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  5%|▌         | 2/39 [00:04<01:18,  2.12s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  8%|▊         | 3/39 [00:05<00:47,  1.32s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 10%|█         | 4/39 [00:05<00:33,  1.06it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 13%|█▎        | 5/39 [00:05<00:25,  1.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 15%|█▌        | 6/39 [00:06<00:22,  1.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 18%|█▊        | 7/39 [00:06<00:19,  1.64it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 21%|██        | 8/39 [00:07<00:17,  1.78it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 23%|██▎       | 9/39 [00:07<00:15,  1.93it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 26%|██▌       | 10/39 [00:09<00:22,  1.32it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 28%|██▊       | 11/39 [00:09<00:17,  1.56it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 31%|███       | 12/39 [00:09<00:15,  1.75it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 33%|███▎      | 13/39 [00:10<00:14,  1.83it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
            "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
            "        2, 2, 2, 2], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 36%|███▌      | 14/39 [00:10<00:12,  1.99it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
            "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
            "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
            "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
            "        2, 2, 2, 2], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 38%|███▊      | 15/39 [00:11<00:11,  2.13it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
            "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
            "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
            "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
            "        2, 2, 2, 2], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 41%|████      | 16/39 [00:11<00:10,  2.18it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
            "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
            "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
            "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
            "        2, 2, 2, 2], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 44%|████▎     | 17/39 [00:11<00:09,  2.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
            "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
            "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
            "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
            "        2, 2, 2, 2], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 46%|████▌     | 18/39 [00:12<00:12,  1.65it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
            "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
            "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
            "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
            "        2, 2, 2, 2], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 49%|████▊     | 19/39 [00:13<00:10,  1.87it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
            "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
            "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
            "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
            "        2, 2, 2, 2], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 51%|█████▏    | 20/39 [00:13<00:09,  2.06it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
            "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
            "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
            "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
            "        2, 2, 2, 2], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 54%|█████▍    | 21/39 [00:14<00:08,  2.20it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
            "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
            "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
            "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
            "        2, 2, 2, 2], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 56%|█████▋    | 22/39 [00:14<00:07,  2.34it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
            "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
            "        2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
            "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
            "        3, 3, 3, 3], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 59%|█████▉    | 23/39 [00:14<00:06,  2.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
            "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
            "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
            "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
            "        3, 3, 3, 3], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 62%|██████▏   | 24/39 [00:15<00:06,  2.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
            "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
            "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
            "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
            "        3, 3, 3, 3], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 64%|██████▍   | 25/39 [00:15<00:05,  2.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
            "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
            "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
            "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
            "        3, 3, 3, 3], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 67%|██████▋   | 26/39 [00:16<00:06,  2.04it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
            "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
            "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
            "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
            "        3, 3, 3, 3], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 69%|██████▉   | 27/39 [00:16<00:05,  2.27it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
            "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
            "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
            "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
            "        3, 3, 3, 3], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 72%|███████▏  | 28/39 [00:17<00:04,  2.40it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
            "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
            "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
            "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
            "        3, 3, 3, 3], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 74%|███████▍  | 29/39 [00:17<00:03,  2.57it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
            "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
            "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
            "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
            "        3, 3, 3, 3], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 77%|███████▋  | 30/39 [00:17<00:03,  2.70it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
            "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
            "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
            "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
            "        4, 4, 4, 4], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 79%|███████▉  | 31/39 [00:18<00:02,  2.78it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
            "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
            "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
            "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
            "        4, 4, 4, 4], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 82%|████████▏ | 32/39 [00:18<00:02,  2.86it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
            "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
            "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
            "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
            "        4, 4, 4, 4], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 85%|████████▍ | 33/39 [00:18<00:02,  2.93it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
            "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
            "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
            "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
            "        4, 4, 4, 4], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 87%|████████▋ | 34/39 [00:18<00:01,  2.97it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
            "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
            "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
            "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
            "        4, 4, 4, 4], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 90%|████████▉ | 35/39 [00:19<00:01,  2.99it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
            "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
            "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
            "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
            "        4, 4, 4, 4], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 92%|█████████▏| 36/39 [00:19<00:00,  3.01it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
            "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
            "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
            "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
            "        4, 4, 4, 4], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 95%|█████████▍| 37/39 [00:19<00:00,  2.98it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
            "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
            "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
            "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
            "        4, 4, 4, 4], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 97%|█████████▋| 38/39 [00:20<00:00,  2.98it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
            "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
            "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
            "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
            "        4, 4, 4, 4], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 39/39 [00:21<00:00,  1.85it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=> result\n",
            "* total: 3,900\n",
            "* correct: 2,007\n",
            "* accuracy: 51.5%\n",
            "* error: 48.5%\n",
            "* macro_f1: 45.6%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### CoOp, CoCoOp 비교하기"
      ],
      "metadata": {
        "id": "BUuWfLBWF8UA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# 메트릭 데이터\n",
        "metrics = ['Base', 'Novel']\n",
        "\n",
        "coop_acc_list = [coop_base_acc, coop_novel_acc]\n",
        "#cocoop_acc_list = [cocoop_base_acc, cocoop_novel_acc]\n",
        "\n",
        "\n",
        "# 막대 너비\n",
        "bar_width = 0.35\n",
        "\n",
        "# X축 위치 설정\n",
        "index = np.arange(len(metrics))\n",
        "\n",
        "# bar plot 생성\n",
        "fig, ax = plt.subplots()\n",
        "\n",
        "bar1 = ax.bar(index, coop_acc_list, bar_width, label='CoOp')\n",
        "#bar2 = ax.bar(index + bar_width, cocoop_acc_list, bar_width, label='CoCoOp')\n",
        "\n",
        "# 제목과 레이블 설정\n",
        "ax.set_ylabel('Scores')\n",
        "ax.set_title('Model Performance Comparison')\n",
        "ax.set_xticks(index + bar_width / 2)\n",
        "ax.set_xticklabels(metrics)\n",
        "ax.legend()\n",
        "\n",
        "# 막대에 값 표시\n",
        "def add_value_labels(bars):\n",
        "    for bar in bars:\n",
        "        height = bar.get_height()\n",
        "        ax.annotate(f'{height:.2f}', xy=(bar.get_x() + bar.get_width() / 2, height),\n",
        "                    xytext=(0, 2),  # 2 points vertical offset\n",
        "                    textcoords='offset points',\n",
        "                    ha='center', va='bottom')\n",
        "\n",
        "add_value_labels(bar1)\n",
        "#add_value_labels(bar2)\n",
        "\n",
        "# 그래프 출력\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "id": "pZQxA8kiBdsj",
        "outputId": "3cc2b5a5-360a-4473-e3e7-e61b4d779724"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "T1wYnG73km3L"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}